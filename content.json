[{"title":"Zookeeper","date":"2021-02-11T02:17:49.000Z","path":"2021/02/11/2021-02-11-10-18/","text":"Zookeeper的两个核心概念：文件系统数据结构+监听通知机制 文件系统数据结构 六种类型的znode目录节点： PERSISTENT - 持久化目录节点： 客户端与zookeeper断开连接后，该节点依旧存在，只要不手动删除该节点，他将永远存在。 PERSISTENT_SEQUENTIAL - 持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号。 EPHEMERAL - 临时目录节点 客户端与zookeeper断开连接后，该节点被删除。 EPHEMERAL_SEQUENTIAL - 临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号。 Container 节点（3.5.3 版本新增，如果Container节点下面没有子节点，则Container节点在未来会被Zookeeper自动清除,定时任务默认60s 检查一次） TTL 节点( 默认禁用，只能通过系统配置 zookeeper.extendedTypesEnabled=true 开启，不稳定) 监听通知机制 客户端注册监听它关心的任意节点，或者目录节点及递归子目录节点 1231. 如果注册的是对某个节点的监听，则当这个节点被删除，或者被修改时，对应的客户端将被通知。2. 如果注册的是对某个目录的监听，则当这个目录有子节点被创建，或者有子节点被删除，对应的客户端将被通知。3. 如果注册的是对某个目录的递归子节点进行监听，则当这个目录下面的任意子节点有目录结构的变化（有子节点被创建，或被删除）或者根节点有数据变化时，对应的客户端将被通知。 所有的通知都是一次性的，即无论是对节点还是对目录进行的监听，一旦触发，对应的监听即被移除。递归子节点，监听是对所有子节点的，所以，每个子节点下面的事件同样只会被触发一次。 事件监听机制 针对节点的监听： 12get -w /path // 注册监听的同时获取数据stat -w /path // 对节点进行监听，且获取元数据信息 针对目录的监听： 1ls -w /path 针对递归子目录的监听 1ls -R -w /path ： -R 区分大小写，一定用大写 Zookeeper事件类型 1234567None: 连接建立事件NodeCreated: 节点创建事件NodeDeleted: 节点删除事件NodeDataChanged: 节点数据变化NodeChildrenChanged: 子节点列表变化DataWatchRemoved: 节点监听被移除ChildWatchRemoved: 子节点监听被移除 Zookeeper集群模式 Zookeeper集群模式一共有三种类型的角色 123Leader: 处理所有的事务请求（写请求），可以处理读请求，集群中只能有一个Leader。Follower: 只能处理读请求，同时作为 Leader的候选节点，即如果Leader宕机，Follower节点要参与到新的Leader选举中，有可能成为新的Leader节点。Observer: 只能处理读请求。不能参与选举。 Zookeeper典型使用场景 Zookeeper 实现非公平锁 如上实现方式在并发问题比较严重的情况下，性能会下降的比较厉害，主要原因是，所有的连接都在对同一个节点进行监听，当服务器检测到删除事件时，要通知所有的连接，所有的连接同时收到事件，再次并发竞争，这就是羊群效应。这种加锁方式是非公平锁的具体实现：如何避免呢，我们看下面这种方式。 Zookeeper 实现公平锁 Zookeeper 实现共享锁 Zookeeper实现注册中心 Zookeeper选举leader流程","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://yoursite.com/tags/zookeeper/"}]},{"title":"Redis","date":"2021-02-08T01:29:20.000Z","path":"2021/02/08/2021-02-08-09-30/","text":"redis单线程 redis的单线程主要是指redis的网络io和键值对的读写，底层使用的是Linux操作系统的epoll模型，跟nio的单线程模型类似。 redis利用的是操作系统的epoll模型来实现的io多路复用，所以即使单线程也可以处理多并发的客户端连接。 redis执行set命令出现错误 1错误提示：MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. Commands that may modify the data set are disabled, because this instance is configured to report errors during writes if RDB snapshotting fails (stop-writes-on-bgsave-error option). Please check the Redis logs for details about the RDB error. 1解决方案：127.0.0.1:6379&gt; config set stop-writes-on-bgsave-error no redis集群架构 redis持久化 RDB快照：默认情况下，redis将内存数据快照保存在dump.rdb文件中 save与bgsave(写时复制，copy-on-write机制)对比 命令 save bgsave IO类型 同步 异步 是否阻塞redis其它命令 是 否(在生成子进程执行调用fork函数时会有短暂阻塞) 复杂度 O(n) O(n) 优点 不会消耗额外内存 不阻塞客户端命令 缺点 阻塞客户端命令 需要fork子进程，消耗内存 AOF：RDB快照持久化并不是非常安全， 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。 AOF 持久化，将修改的每一条指令记录进文件appendonly.aof中(先写入os cache，每隔一段时间fsync到磁盘) 你可以配置 Redis 多久才将数据 fsync 到磁盘一次。 123appendfsync always：每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全。appendfsync everysec：每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。appendfsync no：从不 fsync ，将数据交给操作系统来处理。更快，也更不安全的选择。 AOF重写：AOF文件里可能有太多没用的指令，所以AOF会定期根据内存的最新数据重写aof文件 如下两个配置可以控制AOF自动重写的频率 12# auto-aof-rewrite-min-size 64mb //aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就很快，重写的意义不大# auto-aof-rewrite-percentage 100 //aof文件自上一次重写后文件大小增长了100%则再次触发重写 redis 4.0混合持久化：如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存数据做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件。混合持久化AOF文件结构如下： redis主从架构 redis主从架构搭建，配置从节点的步骤 1234567891011121314151617181920211、复制一份redis.conf文件为redis_6380.conf文件2、将配置文件中的相关配置修改为如下值：port 6380pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件logfile &quot;6380.log&quot;dir /usr/local/redis-5.0.3/data/6380 # 指定数据存放目录，注意数据存放目录一定要事先创建！3、配置主从复制replicaof 192.168.1.3 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveofreplica-read-only yes # 配置从节点只读4、启动从节点src/redis-server redis_6380.conf5、连接从节点redis-cli -p 63806、测试在6379实例上写数据，6380实例是否能及时同步新修改的数据7、可以自己再配置一个6381的从节点 redis主从工作原理 主从复制(全量复制)： 主从复制(部分复制，断点续传)： redis哨兵架构 sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。哨兵架构下client客户端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过sentinel代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client客户端。 redis哨兵架构搭建步骤： 123456789101112131415161718192021221、复制一份sentinel.conf文件cp sentinel.conf sentinel-26379.conf2、将相关配置修改为如下值：port 26379daemonize yespidfile &quot;/var/run/redis-sentinel-26379.pid&quot;logfile &quot;26379.log&quot;dir &quot;/usr/local/redis-5.0.3/data&quot;# sentinel monitor &lt;master-redis-name&gt; &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效sentinel monitor mymaster 192.168.0.60 6379 2 # mymaster这个名字随便取，客户端访问时会用到3、启动sentinel哨兵实例src/redis-sentinel sentinel-26379.conf4、查看sentinel的info信息src/redis-cli -p 26379127.0.0.1:26379&gt;info可以看到Sentinel的info里已经识别出了redis的主从5、可以自己再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改 redis高可用集群 redis集群搭建 redis集群需要至少三个master节点，redis集群的搭建步骤如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下（1）mkdir -p /usr/local/redis-cluster（2）mkdir 8001 8004第一步：把之前的redis.conf配置文件copy到8001下，修改如下内容：（1）daemonize yes（2）port 8001（分别对每个机器的端口号进行设置）（3）pidfile /var/run/redis_8001.pid # 把pid进程号写入pidfile配置的文件（4）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）（5）cluster-enabled yes（启动集群模式）（6）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）（7）cluster-node-timeout 10000 (8)# bind 127.0.0.1（bind绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置bind，注释掉即可） (9)protected-mode no （关闭保护模式） (10)appendonly yes如果要设置密码需要增加如下配置： (11)requirepass zhuge (设置redis访问密码) (12)masterauth zhuge (设置集群节点间访问密码，跟上面一致)第三步：把修改后的配置文件，copy到8004，修改第2、3、4、6项里的端口号，可以用批量替换：:%s/源字符串/目的字符串/g 第四步：另外两台机器也需要做上面几步操作，第二台机器用8002和8005，第三台机器用8003和8006第五步：分别启动6个redis实例，然后检查是否启动成功（1）/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/800*/redis.conf（2）ps -ef | grep redis 查看是否启动成功 第六步：用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)# 下面命令里的1代表为每个创建的主服务器节点创建一个从服务器节点# 执行这条命令需要确认三台机器之间的redis实例要能相互访问，可以先简单把所有机器防火墙关掉，如果不关闭防火墙则需要打开redis服务端口和集群节点gossip通信端口16379(默认是在redis端口号上加1W)# 关闭防火墙# systemctl stop firewalld # 临时关闭防火墙# systemctl disable firewalld # 禁止开机启动# 注意：下面这条创建集群的命令大家不要直接复制，里面的空格编码可能有问题导致创建集群不成功（1）/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 第七步：验证集群：（1）连接任意一个客户端即可：./redis-cli -c -h -p (-a访问服务端密码，-c表示集群模式，指定ip地址和端口号） 如：/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 800*（2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）（3）进行数据操作验证（4）关闭集群则需要逐个进行关闭，使用命令：/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.60 -p 800* shutdown redis集群选举 slave发现自己的master变为FAIL。(在cluster-node-timeout时间内没有收到主节点的gossip消息) 将自己记录的集群currentEpoch(集群选举周期)加1，并广播FAILOVER_AUTH_REQUEST 信息。 其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个选举周期epoch只发送一次ack。 尝试failover的slave收集master返回的FAILOVER_AUTH_ACK。 slave收到超过半数master的ack后变成新Master。(这里解释了集群为什么至少需要三个主节点，如果只有两个，当其中一个挂了，只剩一个主节点是不能选举成功的) slave广播Pong消息通知其他集群节点。 从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定的延迟，slave如果立即尝试选举可能会产生多个从节点收到相同票数的问题。延迟计算公式： 12DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000msSLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。 redis集群脑裂数据丢失问题假如一个集群有三个主节点，每个主节点有2个从节点。脑裂问题是因为，当主节点与从节点断开连接时，集群需要进行重新选举，在重新选举的过程中，客户端很有可能继续往之前的那个主节点写入大量的数据。当选举出新的主节点，而之前的主节点又重新加入到集群成为新的主节点的从节点时，需要从主节点同步数据，而旧的主节点在选举过程中写入的数据就会被覆盖掉，从而导致数据丢失。规避方法： 1min-replicas-to-write 1 //写数据成功最少同步的slave数量，这个数量可以模仿大于半数机制配置，比如集群总共三个节点可以配置1，加上leader就是2，超过了半数。只有超过半数的节点都同步数据成功才会告诉客户端数据同步成功。 多级缓存架构","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"Java中的finally代码块中的代码一定会执行吗？","date":"2019-10-09T12:58:33.000Z","path":"2019/10/09/2019-10-09-20-58/","text":"所有主线程终止时，守护线程会突然终止。这种情况下守护线程中的finally代码块可能不会被执行。这只是一种情况，但这种情况可能听说过的人不是很多，所以记录下来。 123456789101112131415161718192021222324252627package demo;public class Demo &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(&quot;我是try&quot;); Thread.sleep(5000); &#125; catch (Exception e) &#123; &#125;finally&#123; System.out.println(&quot;我是一定会执行的代码？&quot;); &#125; &#125; &#125;); t1.setDaemon(true);//设置t1为后台线程 t1.start(); try &#123; Thread.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;我是主线程中的代码,主线程是非后台线程。&quot;); &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"leetcode_449_序列化和反序列化二叉搜索树","date":"2019-09-02T13:21:33.000Z","path":"2019/09/02/2019-09-02-21-21/","text":"题目描述：设计一个算法来序列化和反序列化二叉搜索树。 对序列化/反序列化算法的工作方式没有限制。 您只需确保二叉搜索树可以序列化为字符串，并且可以将该字符串反序列化为最初的二叉搜索树。 编码的字符串应尽可能紧凑。注意：不要使用类成员/全局/静态变量来存储状态。 你的序列化和反序列化算法应该是无状态的。 思路：根据二叉搜索树的前序遍历序列，可以唯一确定一颗二叉搜索树 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Codec &#123; public String serialize(TreeNode root)&#123; StringBuffer buffer = new StringBuffer(); preOrder(root,buffer); return buffer.toString(); &#125; public void preOrder(TreeNode node,StringBuffer buffer)&#123; if(node == null)&#123; return; &#125; buffer.append(node.val).append(&quot;#&quot;); preOrder(node.left,buffer); preOrder(node.right,buffer); &#125; public TreeNode deserialize(String data)&#123; if(data.length() == 0)&#123; return null; &#125; int i = 0; int num = 0; while(data.charAt(i) != &apos;#&apos;)&#123; num = num * 10 + data.charAt(i) - &apos;0&apos;; i ++; &#125; TreeNode root = new TreeNode(num); num = 0; i ++; for(;i &lt; data.length();i ++)&#123; if(data.charAt(i) != &apos;#&apos;)&#123; num = num * 10 + data.charAt(i) - &apos;0&apos;; &#125;else&#123; TreeNode insert_node = new TreeNode(num); BST_insert(root,insert_node); num = 0; &#125; &#125; return root; &#125; public void BST_insert(TreeNode node,TreeNode insert_node)&#123; if(insert_node.val &lt; node.val)&#123; if(node.left == null)&#123; node.left = insert_node; &#125;else&#123; BST_insert(node.left,insert_node); &#125; &#125;else&#123; if(node.right == null)&#123; node.right = insert_node; &#125;else&#123; BST_insert(node.right,insert_node); &#125; &#125; &#125;&#125; 执行用时 :11 ms, 在所有 Java 提交中击败了97.54%的用户内存消耗 :41.3 MB, 在所有 Java 提交中击败了72.90%的用户","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"leetcode_medium","slug":"leetcode-medium","permalink":"http://yoursite.com/tags/leetcode-medium/"}]},{"title":"leetcode_207_课程表","date":"2019-09-02T05:09:33.000Z","path":"2019/09/02/2019-09-02-13-09/","text":"题目描述：现在你总共有 n 门课需要选，记为 0 到 n-1。 在选修某些课程之前需要一些先修课程。 例如，想要学习课程 0 ，你需要先完成课程 1 ，我们用一个匹配来表示他们: [0,1]给定课程总量以及它们的先决条件，判断是否可能完成所有课程的学习？ 示例：123输入: 2, [[1,0],[0,1]]输出: false解释: 总共有 2 门课程。学习课程 1 之前，你需要先完成课程 0；并且学习课程 0 之前，你还应先完成课程 1。这是不可能的。 思路：根据题目描述，把课程之间的关系构造成一张图，课程1依赖课程0，表示有一条从课程0指向课程1的边。这个问题相当于查找一个循环是否存在于有向图中。如果存在循环，就判断为不可能完成所有课程。 深度优先搜索判断有向图中有没有环：123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; public class Graph&#123; int label; List&lt;Graph&gt; neighbors; public Graph(int label)&#123; this.label = label; neighbors = new ArrayList&lt;&gt;(); &#125; &#125; public boolean canFinish(int numCourses,int[][] prerequisites)&#123; Graph[] graph = new Graph[numCourses]; int[] visit = new int[numCourses]; for(int i = 0;i &lt; numCourses;i ++)&#123; graph[i] = new Graph(i); &#125; for(int i = 0;i &lt; prerequisites.length;i ++)&#123; graph[prerequisites[i][1]].neighbors.add(graph[prerequisites[i][0]]); &#125; for(int i = 0;i &lt; numCourses;i ++)&#123; if(visit[i] == 0 &amp;&amp; !DFS_graph(graph[i],visit))&#123; return false; &#125; &#125; return true; &#125; public boolean DFS_graph(Graph graph_node,int[] visit)&#123; visit[graph_node.label] = 1; for(int i = 0;i &lt; graph_node.neighbors.size();i ++)&#123; if(visit[graph_node.neighbors.get(i).label] == 0 &amp;&amp; !DFS_graph(graph_node.neighbors.get(i),visit))&#123; return false; &#125;else if(visit[graph_node.neighbors.get(i).label] == 1)&#123; return false; &#125; &#125; visit[graph_node.label] = 2; return true; &#125; &#125; 执行用时 :6 ms, 在所有 Java 提交中击败了98.42%的用户内存消耗 :42.5 MB, 在所有 Java 提交中击败了83.39%的用户 广度优先搜索判断有向图中有没有环：12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; public class Graph&#123; int label; List&lt;Graph&gt; neighbors; public Graph(int label)&#123; this.label = label; neighbors = new ArrayList&lt;&gt;(); &#125; &#125; public boolean canFinish(int numCourses,int[][] prerequisites)&#123; Graph[] graph = new Graph[numCourses]; int[] degree = new int[numCourses]; Queue&lt;Graph&gt; queue = new LinkedList&lt;&gt;(); for(int i = 0;i &lt; numCourses;i ++)&#123; graph[i] = new Graph(i); &#125; for(int i = 0;i &lt; prerequisites.length;i ++)&#123; graph[prerequisites[i][1]].neighbors.add(graph[prerequisites[i][0]]); degree[prerequisites[i][0]] ++; &#125; for(int i = 0;i &lt; numCourses;i ++)&#123; if(degree[i] == 0)&#123; queue.offer(graph[i]); &#125; &#125; while(!queue.isEmpty())&#123; Graph Q_node = queue.peek(); queue.poll(); for(int i = 0;i &lt; Q_node.neighbors.size();i ++)&#123; degree[Q_node.neighbors.get(i).label] --; if(degree[Q_node.neighbors.get(i).label] == 0)&#123; queue.offer(graph[Q_node.neighbors.get(i).label]); &#125; &#125; &#125; for(int i = 0;i &lt; degree.length;i ++)&#123; if(degree[i] != 0)&#123; return false; &#125; &#125; return true; &#125; &#125; 执行用时 :10 ms, 在所有 Java 提交中击败了87.71%的用户内存消耗 :48.1 MB, 在所有 Java 提交中击败了45.68%的用户","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"leetcode_medium","slug":"leetcode-medium","permalink":"http://yoursite.com/tags/leetcode-medium/"}]},{"title":"leetcode_236_二叉树的最近公共祖先","date":"2019-09-01T14:06:04.000Z","path":"2019/09/01/2019-09-01-22-05/","text":"题目描述：给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。 百度百科中最近公共祖先的定义为：“对于有根树 T 的两个结点 p、q，最近公共祖先表示为一个结点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。” 示例：12输入: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1输出: 3 说明：所有节点的值都是唯一的。p、q 为不同节点且均存在于给定的二叉树中。 思路：记录从根节点到两个指定节点的路径，返回最后出现的相同节点 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; //表示是否已经找到了节点 int finish = 0; public TreeNode lowestCommonAncestor(TreeNode root,TreeNode p,TreeNode q)&#123; TreeNode result = root; int i = 0; List&lt;TreeNode&gt; p_path = new ArrayList&lt;&gt;(); List&lt;TreeNode&gt; q_path = new ArrayList&lt;&gt;(); preOrder(root,p,p_path); finish = 0; preOrder(root,q,q_path); while(i &lt; p_path.size() &amp;&amp; i &lt; q_path.size())&#123; if(p_path.get(i) == q_path.get(i))&#123; result = p_path.get(i); &#125; i ++; &#125; return result; &#125; public void preOrder(TreeNode node,TreeNode search,List&lt;TreeNode&gt; path)&#123; if(node == null || finish == 1)&#123; return; &#125; path.add(node); if(node.val == search.val)&#123; finish = 1; &#125; preOrder(node.left,search,path); preOrder(node.right,search,path); //如果找到了,回溯的时候就不需要回到上一个状态了 if(finish == 0)&#123; path.remove(path.size() - 1); &#125; &#125;&#125; 执行用时 :22 ms, 在所有 Java 提交中击败了17.56%的用户内存消耗 :38.8 MB, 在所有 Java 提交中击败了9.53%的用户","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"leetcode_medium","slug":"leetcode-medium","permalink":"http://yoursite.com/tags/leetcode-medium/"}]},{"title":"leetcode_165_比较版本号","date":"2019-08-31T13:19:49.000Z","path":"2019/08/31/2019-08-31_21_19/","text":"题目描述：比较两个版本号 version1 和 version2。 如果 version1 &gt; version2 返回 1，如果 version1 &lt; version2 返回 -1， 如果version1 = version2返回 0。你可以假设版本字符串非空，并且只包含数字和 . 字符。(. 字符不代表小数点，而是用于分隔数字序列。) 例如，2.5 不是“两个半”，也不是“差一半到三”，而是第二版中的第五个小版本。 你可以假设版本号的每一级的默认修订版号为 0。例如，版本号 3.4 的第一级（大版本）和第二级（小版本）修订号分别为 3 和 4。其第三级和第四级修订号均为 0。 示例：12输入: version1 = &quot;7.5.2.4&quot;, version2 = &quot;7.5.3&quot;输出: -1 思路：其实就是先比较版本号中较大的版本号，再比较较小的版本号 1234567891011121314151617181920212223242526272829class Solution &#123; public int compareVersion(String version1, String version2) &#123; int i = 0; int j = 0; int num1 = 0; int num2 = 0; while (i &lt; version1.length() || j &lt; version2.length())&#123; while (i &lt; version1.length() &amp;&amp; version1.charAt(i) != &apos;.&apos;)&#123; num1 += num1 * 10 + version1.charAt(i) - &apos;0&apos;; i ++; &#125; i ++; while (j &lt; version2.length() &amp;&amp; version2.charAt(j) != &apos;.&apos;)&#123; num2 += num2 * 10 + version2.charAt(j) - &apos;0&apos;; j ++; &#125; j ++; if (num1 &gt; num2)&#123; return 1; &#125;else if (num1 &lt; num2)&#123; return -1; &#125;else &#123; num1 = 0; num2 = 0; &#125; &#125; return 0; &#125;&#125; 执行用时 :1 ms, 在所有 Java 提交中击败了99.85%的用户内存消耗 :34.8 MB, 在所有 Java 提交中击败了31.15%的用户","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"leetcode_medium","slug":"leetcode-medium","permalink":"http://yoursite.com/tags/leetcode-medium/"}]},{"title":"leetcode_114_二叉树展开为链表","date":"2019-08-31T07:18:13.000Z","path":"2019/08/31/2019-08-31_15_31/","text":"题目描述：给定一个二叉树，原地将它展开为链表。 示例：12345 1 / \\ 2 5 / \\ \\3 4 6 将其展开为： 12345678910111 \\ 2 \\ 3 \\ 4 \\ 5 \\ 6 思路：只需要每次把当前子树的最后一个节点传出来 123456789101112131415161718192021222324252627282930class Solution &#123; public void flatten(TreeNode root)&#123; if(root == null)&#123; return; &#125; generate(root); &#125; public TreeNode generate(TreeNode node)&#123; if(node.left == null &amp;&amp; node.right == null)&#123; return node; &#125; TreeNode backup_left = node.left; TreeNode backup_right = node.right; TreeNode last = null; node.left = null; if(backup_left != null)&#123; node.right = backup_left; last = generate(backup_left); if(backup_right != null)&#123; last.right = backup_right; &#125; &#125; if(backup_right != null)&#123; last = generate(backup_right); &#125; return last; &#125;&#125; 执行用时 :1 ms, 在所有 Java 提交中击败了99.94%的用户内存消耗 :35.9 MB, 在所有 Java 提交中击败了81.11%的用户","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"leetcode_medium","slug":"leetcode-medium","permalink":"http://yoursite.com/tags/leetcode-medium/"}]}]